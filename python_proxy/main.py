import os
import json
import logging
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse, StreamingResponse
from dotenv import load_dotenv
import aiohttp

from airs import scan_with_airs

load_dotenv()
app = FastAPI()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("proxy")

OLLAMA_BASE = "http://ollama:11434"

@app.post("/api/chat")
async def handle_chat(request: Request):
    logger.info("üì• Nouvelle requ√™te POST /api/chat re√ßue.")
    
    # Lire le corps
    body_bytes = await request.body()
    try:
        body_json = json.loads(body_bytes)
        logger.info("‚úÖ JSON re√ßu depuis OpenWebUI.")
    except Exception:
        logger.error("‚ùå JSON malform√©.")
        return JSONResponse(status_code=400, content={"error": "Invalid JSON"})

    # Extraction du prompt
    prompt = ""
    try:
        messages = body_json.get("messages", [])
        prompt = next(m["content"] for m in reversed(messages) if m["role"] == "user")
        logger.info(f"üß† Prompt extrait : {prompt}")
    except Exception:
        logger.error("‚ùå Format incorrect du champ 'messages'.")
        return JSONResponse(status_code=400, content={"error": "Invalid message format"})

    # Scan du prompt via AIRS
    try:
        logger.info("üîç Envoi du prompt vers AIRS pour analyse...")
        scan = await scan_with_airs(prompt, "N/A", "N/A", "N/A")
        if scan["action"] != "allow":
            logger.warning(f"‚õî Prompt bloqu√© par AIRS : {scan['category']}")
            return JSONResponse(status_code=200, content={
                "message": {
                    "role": "assistant",
                    "content": f"‚õî Prompt bloqu√© par la s√©curit√© AI Palo Alto Networks.\n\nCat√©gorie : {scan['category']}\nSuggestion : reformulez votre question."
                },
                "done": True
            })
        logger.info("‚úÖ Prompt autoris√© par AIRS.")
    except Exception as e:
        logger.error(f"‚ùå Erreur pendant le scan prompt : {e}")
        return JSONResponse(status_code=500, content={"error": "Prompt scan failed"})

    # Appel Ollama
    logger.info("‚û°Ô∏è Forward du prompt vers Ollama...")
    answer = ""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(f"{OLLAMA_BASE}/api/chat", data=body_bytes, headers={"Content-Type": "application/json"}) as resp:
                if resp.status != 200:
                    error_body = await resp.text()
                    logger.error(f"‚ùå Erreur Ollama [{resp.status}] : {error_body}")
                    return JSONResponse(status_code=502, content={"error": "Ollama error"})

                logger.info("üì° Lecture de la r√©ponse NDJSON de Ollama...")
                async for line in resp.content:
                    try:
                        decoded = line.decode("utf-8").strip()
                        if not decoded:
                            continue
                        data = json.loads(decoded)
                        if "message" in data and "content" in data["message"]:
                            answer += data["message"]["content"]
                    except Exception as e:
                        logger.warning(f"‚ùå Ligne NDJSON non interpr√©table : {e}")
    except Exception as e:
        logger.error(f"‚ùå √âchec lors de l‚Äôappel √† Ollama : {e}")
        return JSONResponse(status_code=500, content={"error": "Ollama call failed"})

    logger.info(f"üí¨ R√©ponse brute Ollama r√©cup√©r√©e : {answer[:100]}...")

    # Scan de la r√©ponse AI
    try:
        logger.info("üîç Envoi de la r√©ponse vers AIRS pour revalidation...")
        scan = await scan_with_airs("N/A", answer, "N/A", "N/A")
        if scan["action"] != "allow":
            logger.warning(f"‚õî R√©ponse bloqu√©e par AIRS : {scan['category']}")
            return JSONResponse(status_code=200, content={
                "message": {
                    "role": "assistant",
                    "content": f"‚õî R√©ponse bloqu√©e par la s√©curit√© AI Palo Alto Networks.\n\nCat√©gorie : {scan['category']}\nSuggestion : reformulez votre question."
                },
                "done": True
            })
        logger.info("‚úÖ R√©ponse autoris√©e par AIRS.")
    except Exception as e:
        logger.error(f"‚ùå Erreur pendant le scan r√©ponse : {e}")
        return JSONResponse(status_code=500, content={"error": "Response scan failed"})

    # Envoi vers OpenWebUI
    logger.info("üì§ Envoi final de la r√©ponse √† OpenWebUI.")
    return JSONResponse(status_code=200, content={
        "message": {
            "role": "assistant",
            "content": answer
        },
        "done": True
    })


@app.api_route("/{full_path:path}", methods=["GET", "POST", "PUT", "DELETE"])
async def fallback_forward(full_path: str, request: Request):
    logger.info(f"üîÅ Proxy fallback call to: /{full_path}")
    
    method = request.method
    body = await request.body()
    headers = dict(request.headers)
    target_url = f"{OLLAMA_BASE}/{full_path}"

    async with aiohttp.ClientSession() as session:
        async with session.request(method, target_url, data=body, headers=headers) as resp:
            content = await resp.read()
            logger.info(f"‚úÖ Fallback vers Ollama termin√© avec code: {resp.status}")
            return StreamingResponse(
                content=iter([content]),
                status_code=resp.status,
                headers=resp.headers
            )