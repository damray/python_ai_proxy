import aiohttp
import logging
import os

OLLAMA_URL = os.getenv("OLLAMA_BASE_URL", "http://ollama:11434/api/chat")

async def call_ollama(payload: dict) -> dict:
    logging.info(f"üì° Appel vers Ollama √† {OLLAMA_URL}")

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(OLLAMA_URL, json=payload, timeout=120) as response:
                if response.status != 200:
                    logging.error(f"‚ùå Erreur Ollama [{response.status}]: {await response.text()}")
                    return {
                        "message": {
                            "role": "assistant",
                            "content": "‚ùå Erreur de traitement par le mod√®le LLM local (Ollama)."
                        },
                        "done": True
                    }

                data = await response.json()
                logging.info("üß† R√©ponse LLM re√ßue depuis Ollama")
                return data

    except Exception as e:
        logging.exception("‚ùå Exception lors de l'appel √† Ollama")
        return {
            "message": {
                "role": "assistant",
                "content": "‚ùå Exception lors de l‚Äôappel au mod√®le Ollama."
            },
            "done": True
        }
